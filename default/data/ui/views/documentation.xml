<dashboard stylesheet="application.css">
  <label>Documentation</label>
  <row>
    <panel>
      <html>
<body>
  <style>
    .dashboard-view-controls {
      display: none !important;
    }
    .option_block {
      margin-bottom: 0;
    }
    li {
      margin-top: 8px;
    }
  </style>
  <div id="ep_docs">
<h1><img alt="App icon" src="/splunkd/__raw/servicesNS/nobody/event_push/static/appIcon.png" /> Event Push - Splunk Add-On by <a href="https://www.deductiv.net/">Deductiv</a></h1>
<p>This app exports your Splunk search results to remote destinations, so you can do more with your Splunk data. It provides search commands and alert actions to export/push/upload/share your data to multiple destinations of each type. The app must be configured via the Setup dashboard before using it. The setup dashboard includes a connection test feature in the form of a "<strong>Browse</strong>" action for all file-based destinations.</p>
<h2>Supported Export Formats</h2>
<ul>
<li>JSON</li>
<li>Raw Text</li>
<li>KV Pairs</li>
<li>Comma-Delimited (CSV)</li>
<li>Tab-Delimited (TSV)</li>
<li>Pipe-Delimited</li>
</ul>
<h2>File-Based Destinations</h2>
<ul>
<li>Amazon Web Services (AWS) S3-Compatible Object Storage  </li>
<li>Box.com Cloud Storage  </li>
<li>SMB File Shares  </li>
<li>SFTP Servers  </li>
</ul>
<h2>Streaming Destinations</h2>  
<ul>
<li>Splunk HTTP Event Collector  </li>
</ul>
<hr />
<h2>AWS S3-Compatible Object Storage (epawss3)</h2>
<p>Export Splunk search results to AWS S3-compatible object storage. Connections can be configured to authenticate using OAuth credentials or the assumed role of the search head EC2 instance.  </p>
<h3>Capabilities</h3>
<ul>
<li>configure_ep_aws_s3_read  </li>
<li>configure_ep_aws_s3_write  </li>
</ul>
<h3>Search Command Syntax</h3>
<pre><code>&lt;search&gt; | epawss3  
        target=&lt;target name/alias&gt;  
        bucket=&lt;bucket&gt;  
        outputfile=&lt;output path/filename&gt;  
        outputformat=[json|raw|kv|csv|tsv|pipe]  
        fields="&lt;comma-delimited fields list&gt;"  
        compress=[true|false]  </code></pre>
<h3>Arguments</h3>
<ul>
<li>
<h4>Target</h4>
<p><strong>Syntax:</strong> target=&lt;target name/alias&gt;</p><p>
<strong>Description:</strong> The name/alias of the destination connection</p><p>
<strong>Default:</strong> The target specified as the default within the setup dashboard  </p>
</li>
<li>
<h4>Bucket</h4>
<p><strong>Syntax:</strong> bucket=&lt;bucket name&gt;</p><p>
<strong>Description:</strong> The name of the destination S3 bucket</p><p>
<strong>Default:</strong> Specified within the target configuration  </p>
</li>
<li>
<h4>Output File</h4>
<p><strong>Syntax:</strong> outputfile=&lt;[folder/]file name&gt;</p><p>
<strong>Description:</strong> The name of the file to be written to the destination. If compression=true, a .gz extension will be appended. If compression is not specified and the filename ends in .gz, compression will automatically be applied.</p><p>
<strong>Default:</strong> <code>app_username_epoch.ext</code> (e.g. <code>search_admin_1588000000.log</code>).  json=.json, csv=.csv, tsv=.tsv, pipe=.log, kv=.log, raw=.log</p><p>
<strong>Keywords:</strong> <code>__now__</code>=epoch, <code>__today__</code>=date in yyyy-mm-dd format, <code>__nowft__</code>=timestamp in yyyy-mm-dd_hhmmss format.  </p>
</li>
<li>
<h4>Output Format</h4>
<p><strong>Syntax:</strong> outputformat=[json|raw|kv|csv|tsv|pipe]</p><p>
<strong>Description:</strong> The format for the exported search results</p><p>
<strong>Default:</strong> <em>csv</em>  </p>
</li>
<li>
<h4>Fields</h4>
<p><strong>Syntax:</strong> fields="field1, field2, field3"</p><p>
<strong>Description:</strong> Limit the fields to be written to the exported file. Wildcards are supported.</p><p>
<strong>Default:</strong> All (*)  </p>
</li>
<li>
<h4>Compression</h4>
<p><strong>Syntax:</strong> compress=[true|false]</p><p>
<strong>Description:</strong> Create the file as a .gz compressed archive</p><p>
<strong>Default:</strong> Specified within the target configuration  </p>
</li>
</ul>
<hr />
<h2>Box Event Push (epbox)</h2>
<p>Export Splunk search results to Box cloud storage. Box must be configured with a Custom App using Server Authentication (with JWT) and a certificate generated. Then, the app must be submitted for approval by the administrator. The administrator should create a folder within the app's account and share it with the appropriate users.  </p>
<h3>Capabilities</h3>
<ul>
<li>configure_ep_box_read  </li>
<li>configure_ep_box_write  </li>
</ul>
<h3>Search Command Syntax</h3>
<pre><code>&lt;search&gt; | epbox  
        target=&lt;target name/alias&gt;  
        outputfile=&lt;output path/filename&gt;  
        outputformat=[json|raw|kv|csv|tsv|pipe]  
        fields="&lt;comma-delimited fields list&gt;"  
        compress=[true|false]  </code></pre>
<h3>Arguments</h3>
<ul>
<li>
<h4>Target</h4>
<p><strong>Syntax:</strong> target=&lt;target name/alias&gt;</p><p>
<strong>Description:</strong> The name/alias of the destination connection</p><p>
<strong>Default:</strong> The target specified as the default within the setup dashboard  </p>
</li>
<li>
<h4>Output File</h4>
<p><strong>Syntax:</strong> outputfile=&lt;[folder/]file name&gt;</p><p>
<strong>Description:</strong> The name of the file to be written to the destination. If compression=true, a .gz extension will be appended. If compression is not specified and the filename ends in .gz, compression will automatically be applied.</p><p>
<strong>Default:</strong> <code>app_username_epoch.ext</code> (e.g. <code>search_admin_1588000000.log</code>).  json=.json, csv=.csv, tsv=.tsv, pipe=.log, kv=.log, raw=.log</p><p>
<strong>Keywords:</strong> <code>__now__</code>=epoch, <code>__today__</code>=date in yyyy-mm-dd format, <code>__nowft__</code>=timestamp in yyyy-mm-dd_hhmmss format.  </p>
</li>
<li>
<h4>Output Format</h4>
<p><strong>Syntax:</strong> outputformat=[json|raw|kv|csv|tsv|pipe]</p><p>
<strong>Description:</strong> The format for the exported search results</p><p>
<strong>Default:</strong> <em>csv</em>  </p>
</li>
<li>
<h4>Fields</h4>
<p><strong>Syntax:</strong> fields="field1, field2, field3"</p><p>
<strong>Description:</strong> Limit the fields to be written to the exported file. Wildcards are supported.</p><p>
<strong>Default:</strong> All (*)  </p>
</li>
<li>
<h4>Compression</h4>
<p><strong>Syntax:</strong> compress=[true|false]</p><p>
<strong>Description:</strong> Create the file as a .gz compressed archive</p><p>
<strong>Default:</strong> Specified within the target configuration  </p>
</li>
</ul>
<hr />
<h2>SMB Event Push Search Command (epsmb)</h2>
<p>Export Splunk search results to SMB file shares.  </p>
<h3>Capabilities</h3>
<ul>
<li>configure_ep_smb_read  </li>
<li>configure_ep_smb_write  </li>
</ul>
<h3>Search Command Syntax</h3>
<pre><code>&lt;search&gt; | epsmb  
        target=&lt;target name/alias&gt;  
        outputfile=&lt;output path/filename&gt;  
        outputformat=[json|raw|kv|csv|tsv|pipe]  
        fields="&lt;comma-delimited fields list&gt;"  
        compress=[true|false]  </code></pre>
<h3>Arguments</h3>
<ul>
<li>
<h4>Target</h4>
<p><strong>Syntax:</strong> target=&lt;target name/alias&gt;</p><p>
<strong>Description:</strong> The name/alias of the destination connection</p><p>
<strong>Default:</strong> The target specified as the default within the setup dashboard  </p>
</li>
<li>
<h4>Output File</h4>
<p><strong>Syntax:</strong> outputfile=&lt;[folder/]file name&gt;</p><p>
<strong>Description:</strong> The name of the file to be written to the destination. If compression=true, a .gz extension will be appended. If compression is not specified and the filename ends in .gz, compression will automatically be applied.</p><p>
<strong>Default:</strong> <code>app_username_epoch.ext</code> (e.g. <code>search_admin_1588000000.log</code>).  json=.json, csv=.csv, tsv=.tsv, pipe=.log, kv=.log, raw=.log</p><p>
<strong>Keywords:</strong> <code>__now__</code>=epoch, <code>__today__</code>=date in yyyy-mm-dd format, <code>__nowft__</code>=timestamp in yyyy-mm-dd_hhmmss format.  </p>
</li>
<li>
<h4>Output Format</h4>
<p><strong>Syntax:</strong> outputformat=[json|raw|kv|csv|tsv|pipe]</p><p>
<strong>Description:</strong> The format for the exported search results</p><p>
<strong>Default:</strong> <em>csv</em>  </p>
</li>
<li>
<h4>Fields</h4>
<p><strong>Syntax:</strong> fields="field1, field2, field3"</p><p>
<strong>Description:</strong> Limit the fields to be written to the exported file. Wildcards are supported.</p><p>
<strong>Default:</strong> All (*)  </p>
</li>
<li>
<h4>Compression</h4>
<p><strong>Syntax:</strong> compress=[true|false]</p><p>
<strong>Description:</strong> Create the file as a .gz compressed archive</p><p>
<strong>Default:</strong> Specified within the target configuration  </p>
</li>
</ul>
<hr />
<h2>SFTP Event Push Search Command (epsftp)</h2>
<p>Export Splunk search results to SFTP servers.  </p>
<h3>Capabilities</h3>
<ul>
<li>configure_ep_sftp_read  </li>
<li>configure_ep_sftp_write  </li>
</ul>
<h3>Search Command Syntax</h3>
<pre><code>&lt;search&gt; | epsftp  
        target=&lt;target name/alias&gt;  
        outputfile=&lt;output path/filename&gt;  
        outputformat=[json|raw|kv|csv|tsv|pipe]  
        fields="&lt;comma-delimited fields list&gt;"  
        compress=[true|false]  </code></pre>
<h3>Arguments</h3>
<ul>
<li>
<h4>Target</h4>
<p><strong>Syntax:</strong> target=&lt;target name/alias&gt;</p><p>
<strong>Description:</strong> The name/alias of the destination connection</p><p>
<strong>Default:</strong> The target specified as the default within the setup dashboard  </p>
</li>
<li>
<h4>Output File</h4>
<p><strong>Syntax:</strong> outputfile=&lt;[folder/]file name&gt;</p><p>
<strong>Description:</strong> The name of the file to be written to the destination. If compression=true, a .gz extension will be appended. If compression is not specified and the filename ends in .gz, compression will automatically be applied.</p><p>
<strong>Default:</strong> <code>app_username_epoch.ext</code> (e.g. <code>search_admin_1588000000.log</code>).  json=.json, csv=.csv, tsv=.tsv, pipe=.log, kv=.log, raw=.log</p><p>
<strong>Keywords:</strong> <code>__now__</code>=epoch, <code>__today__</code>=date in yyyy-mm-dd format, <code>__nowft__</code>=timestamp in yyyy-mm-dd_hhmmss format.  </p>
</li>
<li>
<h4>Output Format</h4>
<p><strong>Syntax:</strong> outputformat=[json|raw|kv|csv|tsv|pipe]</p><p>
<strong>Description:</strong> The format for the exported search results</p><p>
<strong>Default:</strong> <em>csv</em>  </p>
</li>
<li>
<h4>Fields</h4>
<p><strong>Syntax:</strong> fields="field1, field2, field3"</p><p>
<strong>Description:</strong> Limit the fields to be written to the exported file. Wildcards are supported.</p><p>
<strong>Default:</strong> All (*)  </p>
</li>
<li>
<h4>Compression</h4>
<p><strong>Syntax:</strong> compress=[true|false]</p><p>
<strong>Description:</strong> Create the file as a .gz compressed archive</p><p>
<strong>Default:</strong> Specified within the target configuration  </p>
</li>
</ul>
<hr />
<h2>Splunk HEC Event Push (ephec)</h2>
<p>Push Splunk search results to Splunk HTTP Event Collector (HEC) listener.</p>
<h3>Capabilities</h3>
<ul>
<li>configure_ep_hec_read  </li>
<li>configure_ep_hec_write  </li>
</ul>
<h3>Search Command Syntax</h3>
<pre><code>&lt;search&gt; | ephec  
        target=&lt;target name/alias&gt;  
        host=[host_value|$host_field$]  
        source=[source_value|$source_field$]  
        sourcetype=[sourcetype_value|$sourcetype_field$]  
        index=[index_value|$index_field$]  </code></pre>
<h4>Arguments</h4>
<ul>
<li>
<h4>Host</h4>
<p><strong>Syntax:</strong> host=[host_value|$host_field$]</p><p>
<strong>Description:</strong> Field or string to be assigned to the host field on the pushed event</p><p>
<strong>Default:</strong> $host$, or if not defined, the hostname of the sending host (from inputs.conf)  </p>
</li>
<li>
<h4>Source</h4>
<p><strong>Syntax:</strong> source=[source_value|$source_field$]</p><p>
<strong>Description:</strong> Field or string to be assigned to the source field on the pushed event</p><p>
<strong>Default:</strong> $source$, or if not defined, it is omitted  </p>
</li>
<li>
<h4>Sourcetype</h4>
<p><strong>Syntax:</strong> sourcetype=[sourcetype_value|$sourcetype_field$]</p><p>
<strong>Description:</strong> Field or string to be assigned to the sourcetype field on the pushed event</p><p>
<strong>Default:</strong> $sourcetype$, or if not defined, json  </p>
</li>
<li>
<h4>Index</h4>
<p><strong>Syntax:</strong> index=[index_value|$index_field$]</p><p>
<strong>Description:</strong> The remote index in which to store the pushed event</p><p>
<strong>Default:</strong> $index$, or if not defined, the remote endpoint's default.  </p>
</li>
</ul>
<hr />
<h2>Support</h2>
<p>Having trouble with the app? Feel free to <a href="mailto:contact@deductiv.net">email us</a> and we’ll help you sort it out. You can also <a href="https://splunk-usergroups.slack.com/team/U30E9LS79">reach the author</a> on the Splunk Community Slack.  </p>
<h2>Roadmap</h2>
<p>We welcome your input on our app feature roadmap, which can be found on <a href="https://trello.com/b/YbFOsuKJ/event-push-add-on-for-splunk-by-deductiv">Trello</a>.</p>
</div>
</body>
</html>
    </panel>
  </row>
</dashboard>